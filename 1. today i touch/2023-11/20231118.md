- https://www.youtube.com/watch?v=sgVUM3bF6Ds Erwin the best commander: boldness, truth, goal-oriented, wise with specific plans and backups, sacrifice if needed
- https://www.youtube.com/watch?v=eOnzPjZsMJs luật tương ứng, Law of Correspondence presented by An Le, you are becoming more miraculous
- CSV export v2 must be those coming with [cursors](https://www.postgresqltutorial.com/postgresql-plpgsql/plpgsql-cursor/) under the hood, but DB cursors can be orphan (unclosed) hence occupying DB disk. Let's find a way to migrate it safely.
	- The CSV export derives data in the application layer, it means there must be a way to build data with scrolling.
	- There are two approaches, (1) previously declared cursor with custom argument, then simply OPEN cursor vs. (2) declare and fetch in time
		- (1) is likely an explicit solid abstraction, while (2) is a patch on existing SQL queries. I think I will stick to (2) for being generic to all kinds of SQLs
		- The problem of closing cursor is still a problem; [WITHOUT HOLD](https://www.postgresql.org/docs/current/sql-declare.html#:~:text=WITH%20HOLD%20specifies%20that%20the,WITHOUT%20HOLD%20is%20the%20default.) is safer/more resilience to the DB server
			- "Unless `WITH HOLD` is specified, **the cursor created by this command can only be used within the current transaction**. Thus, `DECLARE` without `WITH HOLD` is useless outside a transaction block: the cursor would survive only to the completion of the statement. Therefore PostgreSQL reports an error if such a command is used outside a transaction block. Use [`BEGIN`](https://www.postgresql.org/docs/current/sql-begin.html "BEGIN") and [`COMMIT`](https://www.postgresql.org/docs/current/sql-commit.html "COMMIT") (or [`ROLLBACK`](https://www.postgresql.org/docs/current/sql-rollback.html "ROLLBACK")) to define a transaction block."
				- Given CSV export is a zero WRITE, READ heavy operation, 
			- Better read these cautions in SQL-DECLARE carefully 
	- https://github.com/rails/rails/issues/28085 5 years ago, Sam did open an issue related to integrate this into AR batches
	- https://github.com/afair/postgresql_cursor/blob/e519168/lib/postgresql_cursor/cursor.rb#L247-L251
		- the name is `cursor_` secure-random generated
		- [LOC](https://github.com/afair/postgresql_cursor/blob/e519168/lib/postgresql_cursor/cursor.rb#L295) `cursor_tuple_fraction` Sets the PostgreSQL cursor_tuple_fraction value = 1.0 to assume all rows will be fetched
		- known issues
			- socket descriptor on long run (7hours+) https://github.com/afair/postgresql_cursor/issues/64
			- enum not serialized based on Rails enum https://github.com/afair/postgresql_cursor/issues/57
- Trading doesn't create wealth, it settles goods on (1) "how much things are?" and (2) "what are you at?". If creating a pen cost a fixed amount X of resources, a country that is capable of creating 10 pen with the same X is 10 times richer
- I should follow Paul Graham: writing short essays to unveil my dumb.