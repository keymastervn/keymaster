- Heavy read -> sync over reading sources
- https://www.honeybadger.io/blog/avoid-race-condition-in-rails/
	- race condition is easy to happen, not easy to reproduce, causing hard inconsistency
- https://en.wikipedia.org/wiki/OpenAI#:~:text=instead.%5B22%5D-,Motives,-%5Bedit%5D
	- Some scientists, such as [Stephen Hawking](https://en.wikipedia.org/wiki/Stephen_Hawking "Stephen Hawking") and [Stuart Russell](https://en.wikipedia.org/wiki/Stuart_J._Russell "Stuart J. Russell"), have articulated concerns that if advanced AI someday gains the ability to re-design itself at an ever-increasing rate, an unstoppable "[intelligence explosion](https://en.wikipedia.org/wiki/Intelligence_explosion "Intelligence explosion")" could lead to [human extinction](https://en.wikipedia.org/wiki/Human_extinction "Human extinction"). Musk characterizes AI as humanity's "biggest existential threat."[[23]](https://en.wikipedia.org/wiki/OpenAI#cite_note-23) OpenAI's founders structured it as a non-profit so that they could focus its research on creating a positive long-term human impact.
	- Musk and Altman's counter-intuitive strategy of trying to reduce the risk that AI will cause overall harm, by giving AI to everyone, is controversial among those who are concerned with [existential risk from artificial intelligence](https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence "Existential risk from artificial general intelligence"). Philosopher [Nick Bostrom](https://en.wikipedia.org/wiki/Nick_Bostrom "Nick Bostrom") is skeptical of Musk's approach: "If you have a button that could do bad things to the world, you don't want to give it to everyone."[[22]](https://en.wikipedia.org/wiki/OpenAI#cite_note-wired_inside-22) During a 2016 conversation about the technological singularity, Altman said that "we don't plan to release all of our source code" and mentioned a plan to "allow wide swaths of the world to elect representatives to a new governance board". Greg Brockman stated that "Our goal right now... is to do the best thing there is to do. It's a little vague."[[31]](https://en.wikipedia.org/wiki/OpenAI#cite_note-31)
- https://www.enterprisedb.com/blog/what-skip-locked-postgresql-95 FOR UPDATE SKIP LOCKED, DB persistence queue without mutex for concurrent workers
	- A queue implemented in the RDBMS will never match the performance of a fast dedicated queueing system, even one that makes the same atomicity and durability guarantees as PostgreSQL. Using SKIP LOCKED is better than existing in-database approaches, but you’ll still go faster using a dedicated and highly optimised external queueing engine.
	- how about the approach to keep sidekiq transaction in the same transaction with DB on rollback to implement the outbox-pattern?