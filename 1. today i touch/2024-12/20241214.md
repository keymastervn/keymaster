- https://www.lesswrong.com/posts/5jjk4CDnj9tA7ugxr/openai-email-archives-from-musk-v-altman OpenAI Email Archives (from Musk v. Altman and OpenAI blog) - can be a movie series.
	- https://openai.com/index/elon-musk-wanted-an-openai-for-profit/ you should read this first on how Elon sucks, note: a one-side story
		- https://openai.com/index/openai-elon-musk/ and this previous one
	- "I've attached the offer letter template we've been using, with a salary of $175k. Here's the email template I've been sending people:"
	- "---- OpenAI is a non-profit artificial intelligence research company with the goal of advancing digital intelligence in the way that is most likely to benefit humanity as a whole, unencumbered by an obligation to generate financial returns.\n The underlying philosophy of our company is to disseminate AI technology as broadly as possible as an extension of all individual human wills, ensuring, in the spirit of liberty, that the power of digital intelligence is not overly concentrated and evolves toward the future desired by the sum of humanity. \n The outcome of this venture is uncertain and the pay is low compared to what others will offer, but we believe the goal and the structure are right. We hope this is what matters most to the best in the field."
	- "that deepmind is going to give everyone in openAI massive counteroffers tomorrow to try to kill it.\n do you have any objection to me proactively increasing everyone's comp by 100-200k per year? i think they're all motivated by the mission here but it would be a good signal to everyone we are going to take care of them over time."
		- then after defending successfully "Our most important consideration is recruitment of the best people. The output of any company is the vector sum of the people within it. If we are able to attract the most talented people over time and our direction is correctly aligned, then OpenAI will prevail."
		- "I would recommend paying close attention to people who haven't **completed their grad or even undergrad, but are obviously brilliant**. Better to have them join before they achieve a breakthrough", with this mindset, I would rate Elon 10-star
	- https://slatestarcodex.com/2015/12/17/should-ai-be-open/
		- "H.G. Wells’ 1914 sci-fi book [The World Set Free](https://en.wikipedia.org/wiki/The_World_Set_Free) did a pretty good job predicting nuclear weapons:..." "Wells believed the coming atomic bombs would be so deadly that we would inevitably create a utopian one-world government to prevent them from ever being used. Sorry, Wells. It was a nice thought."
		- Ilya: "The article is concerned with a hard takeoff scenario: **if a hard takeoff occurs, and a safe AI is harder to build than an unsafe one**, then by opensorucing everything, we make it easy for someone unscrupulous with access to overwhelming amount of hardware to build an unsafe AI. **As we get closer to building AI, it will make sense to start being less open**. The Open in openAI means that everyone should benefit from the fruits of AI after its built, but it's totally OK to not share the science"
	- Musk: "The probability of DeepMind creating a deep mind increases every year. Maybe it doesn't get past 50% in 2 to 3 years, but it likely moves past 10%." "**This doesn't mean we should rush out and hire weak talent**. I agree that nothing good would be achieved by that. What we need to do is redouble our efforts to seek out the best people in the world, do whatever it takes to bring them on board and imbue the company with a high sense of urgency"
		- Another clap to Musk, he knew he was working to create a special thing.
		- About the DeepMind's declining progress... could it be a politics issue? Could it be a case when the people were making it too fast, they would be too soon replaced? Perhaps :-) 
	- Ilya: "We can't build AI today because we lack key ideas (computers may be too slow, too, but we can't tell). Powerful ideas are produced by top people. Massive clusters help, and are very worth getting, but they play a less important role. We will be able to achieve a conventionally significant result in the next 6 to 9 months, simply because the people we already have are very good. Achieving a field-altering result will be harder, riskier, and take longer. But we have a not unreasonable plan for that as well."
	- Elon, on replying Greg: "We need to do what it takes to get the top talent. Let's go higher. If, at some point, we need to revisit what existing people are getting paid, that's fine." "Deepmind is causing me extreme mental stress. If they win, it will be really bad news with their one mind to rule the world philosophy. They are obviously making major progress and well they should, given the talent level over there."
	- Sam Teller: "he (Mark Zuckerberg) said, the machines will always be subservient, not “superhuman.”"
	- Musk: "**History unequivocally illustrates that a powerful technology is a double-edged sword. It would be foolish to assume that AI, arguably the most powerful of all technologies, only has a single edge**. \nThe recent example of Microsoft's AI chatbot shows how quickly it can turn incredibly negative. The wise course of action is to approach the advent of AI with caution and ensure that its power is widely distributed and not controlled by any one company or person.\nThat is why we created OpenAI."
	- on the MSFT deal -> it is not easy for us to read such deal, because it is mostly confidentally private.
		- Elon: "This actually made me feel nauseous. It sucks and is exactly what I would expect from them." :lol:, Microsoft wanted more marketing ie. CNTK v2 from OpenAI 
		- "Let’s just say that we are willing to have Microsoft donate spare computing time to OpenAI and have that be known, but we want do any contract or agree to “evangelize”. They can turn us off at any time and we can leave at any time."
		- "We should just do this low key. No certainty either way. No contract."
			- Elon is smart, viciously smart 
		- "Microsoft is now willing to do the agreement for a full $50m with “good faith effort at OpenAI's sole discretion” and full mutual termination rights at any time. No evangelizing. No strings attached. No looking like lame Microsoft marketing pawns. Ok to move ahead?" "Fine by me if they don't use this in active messaging. Would be worth way more than $50M not to seem like Microsoft's marketing bitch."
		- Yep, lesson learnt. If MSFT missed this, the story now would be very different. Perhaps, Sam sold his heart to them instead :-)
		- Ilya: "- In the old days, a large cluster could help you run more experiments, but it could not help with running a single large experiment quickly. \n For this reason, an academic lab could compete with Google, because Google's only advantage was the ability to run many experiments. This is not a great advantage." -> the Achilles' heel.
			- "- Currently, every Dota experiment uses 1000+ cores, and it is only for the small 1v1 variant, and on extremely small neural network policies. We will need more compute to just win the 1v1 variant. To win the full 5v5 game, we will need to run fewer experiments, where each experiment is at least 1 order of magnitude larger (possibly more!)."
			- "- We will solve the 1v1 version of the game in 1 month. Fans of the game care about 1v1 a fair bit."
			- "- We are now at a point where a _single experiment_ consumes 1000s of cores, and where adding more distributed compute increases performance."
			- "Self play as a key path to AGI: - Self-play lets us get "something out of nothing." The rules of a competitive game can be simple, but the best strategy for playing this game can be immensely complex. [motivating example: [https://www.youtube.com/watch?v=u2T77mQmJYI](https://www.youtube.com/watch?v=u2T77mQmJYI)]."
		- Ilya: "**We're still missing several key ideas necessary for building AGI. How can we use a system's understanding of “thing A” to learn “thing B”** (e.g. can I teach a system to count, then to multiply, then to solve word problems)? How do we build curious systems? How do we train a system to discover the deep underlying causes of all types of phenomena — to act as a scientist? How can we build a system that adapts to new situations on which it hasn’t been trained on precisely (e.g. being asked to apply familiar concepts in an unfamiliar situation)? But given enough hardware to run the relevant experiments in 7–10 days, history indicates that the right algorithms will be found, just like physicists would quickly figure out how the universe works if only they had a big enough particle accelerator."
			- He found the "true intelligence" issue: conceptualize other concepts. I think AI "was" stuck because we human has been experiencing free-will purposes, but AI, does not, it is limited to learn what we have done and serve the same thing.
			- He even said "There is good reason to believe that deep learning hardware will speed up 10x each year for the next four to five years. The world is used to the comparatively leisurely pace of Moore’s Law, and is not prepared for the drastic changes in capability this hardware acceleration will bring. This speedup will happen not because of smaller transistors or faster clock cycles; it will happen because like the brain, neural networks are intrinsically parallelizable, and new highly parallel hardware is being built to exploit this.", again, how could Intel ghost this prediction?
			- "Increase our headcount: from 55 (July 2017) to 80 (January 2018) to 120 (January 2019) to 200 (January 2020). We’ve learned how to organize our current team, and we’re now bottlenecked by number of smart people trying out ideas."
		- On "Re: Current State"
			- Now the game Secret-Hitler
			- Musk: "As mentioned, my experience with boards (assuming they consist of good, smart people) is that they are rational and reasonable. There is basically never a real hardcore battle where an individual board vote is pivotal, so this is almost certainly (sure hope so) going to be a moot point."
			- Ilya: "Yesterday while we were considering making our final commitment given the non-solicit agreement, we realized we'd made a mistake. We have several important concerns that we haven't raised with either of you. **We didn't raise them because we were afraid to: we were afraid of harming the relationship, having you think less of us, or losing you as partners**.... \nAs an example, you said that you needed to be CEO of the new company so that everyone will know that you are the one who is in charge, even though you also stated that you hate being CEO and would much rather not be CEO. \n Thus, **we are concerned that as the company makes genuine progress towards AGI, you will choose to retain your absolute control** of the company despite current intent to the contrary. We disagree with your statement that our ability to leave is our greatest power, because once the company is actually on track to AGI, the company will be much more important than any individual."
				- I strongly believe Ilya and Greg were right about Elon at that moment. However, Ilya wasn't right about Sam Altman, and Greg is with him at this moment, they are now very political. IMHO Musk is great, but he is dangerous at high stake. Poor Ilya and his "Superalignment" project
					- Now, he cofounds https://ssi.inc/ "We are assembling a lean, cracked team of the world’s best engineers and researchers dedicated to focusing on SSI and nothing else."
				- There should be a story of Anthropic
				- For Sam "When Greg and I are stuck, you've always had an answer that turned out to be deep and correct. You've been thinking about the ways forward on this problem extremely deeply and thoroughly. Greg and I understand technical execution, but we don't know how structure decisions will play out over the next month, year, or five years.\n **We don't understand why the CEO title is so important to you. Your stated reasons have changed, and it's hard to really understand what's driving it.** Is AGI truly your primary motivation? How does it connect to your political goals? How has your thought process changed over time?"
		- Musk: "Guys, I've had enough. This is the final straw. Either go do something on your own or **continue with OpenAI as a nonprofit**. I will no longer fund OpenAI until you have made a firm commitment to stay or I'm just being a fool who is essentially providing free funding for you to create a startup. Discussions are over"
		- On ICO
			- Musk: "I have considered the ICO approach and will not support it. **In my opinion, that would simply result in a massive loss of credibility for OpenAI and everyone associated with the ICO**. If something seems too good to be true, it is. This was, in my opinion, an unwise diversion." -> public offering doesn't work and ICO is simply a lie to Elon.
		- On "I feel I should reiterate"
			- Musk: "OpenAI reminds me of Bezos and Blue Origin. They are hopelessly behind SpaceX and getting worse, but the ego of Bezos has him insanely thinking that they are not!"
			- When Musk replied on the 20B valuation of OpenAI, Shivon Zilis said to Sam: "Call if you'd like additional context, but overall recommendation is don't text back immediately"
		- done unrevealed
	- https://www.lesswrong.com/posts/5jjk4CDnj9tA7ugxr/openai-email-archives-from-musk-v-altman-and-openai-blog?commentId=wtnFGmiBbu6qBLxq7
		- "Ilya leaving OpenAI was a huge loss - he seemed to genuinely believe in the original mission, unlike Sam and Elon who seemed to be at least partly motivated by personal ambition and ego"
	- relevancy
		- ![[Screenshot 2024-12-14 at 15.24.21.png]]
- https://gamerant.com/the-game-awards-2024-best-adaptation-winner/
	- https://www.youtube.com/watch?v=YOBJ_TZO1lI Arcane: Viktor II The End of Pursuit
		- t=2:25 "Those who shine brightest often burn fastest"
			- After Ngoc, I probably wanted to excel at everything in my life
		- t=4:35 "All systems have limits"
		- t=4:50 "Knowledge is a paradox, the more one understands, the more one realizes the vastness of his ignorance"
		- "From nothing to godhood all just to learn the falsehood of perfection" https://www.youtube.com/watch?v=YOBJ_TZO1lI&lc=UgwUcgZevyvFX0MC8wp4AaABAg
	- I have read many essays written about Neon Genesis Evangelion to de-abstract its concepts. With Arcane, it is close to a/the simplest interpretation.
- https://communist.red/read/ Marxist reading guide
	- ![[Screenshot 2024-12-14 at 17.10.31.png]] hmm, fine
- https://www.youtube.com/watch?v=5kwFt6z3gaI
	- t=6:20 afraid of a coup, replaced Hassan, their god hero :straight-face:
	- t=8:10 it was not a surprised, it is written down 🤔
	- Israeli actively weakened SAA, for the interest of Turkish?
	- it was full of deceptions
	- t=16:50 now you have to dig tunnels to prevent drone's recon, it is not easy for defenders like before because everything are unveiled
	- t=19:00 HTS took M5 first, that caused the strategic failure of SAA at Aleppo, very well-planned
	- t=24:35 "why the Syrian Army collapsed?"
		- how well-trained motivated and capable formations were all removed from the Aleppo sector.
		- t=28:30 "jamming communications and faking withdraw" -> jamming I know, faking withdraw is actually hilarious