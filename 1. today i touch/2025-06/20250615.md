- https://www.appropedia.org/Appropriate_technology
	- Gandhi: self-reliance
	- Schumacher: Small is Beautiful
	- Papanek: Design for Human Scale
	- Albertson and Faulkner: Appropriate hard and soft technologies
	- The Water Decade: Village-level operation and maintenance
	- Paul Polak: The Death of Appropriate Technology organizations
- https://blog.pragmaticengineer.com/how-to-lead-a-project-in-software-development/
- https://www.linkedin.com/posts/gergelyorosz_wow-google-experiencing-the-same-lesson-activity-7339581057450557440-3MIN?utm_source=share&utm_medium=member_desktop&rcm=ACoAABfZmikB1Bxn9NAEt034yXkdpzkaFnkA9rg
	- On Thursday, Google Cloud had an outage lasting 7 hours: and a good time of the downtime was due to the same thundering herd problem. From Google’s postmortem:  “Within some of our larger regions, such as us-central-1, as Service Control tasks restarted, **it created a herd effect on the underlying infrastructure it depends on** (i.e. that Spanner table), overloading the infrastructure. **Service Control did not have the appropriate randomized exponential backoff implemented to avoid this**.  It took up to ~2h 40 mins to fully resolve in us-central-1 as we throttled task creation to minimize the impact on the underlying infrastructure and routed traffic to multi-regional databases to reduce the load.”  
	- Google’s action item to improve here:  “We will audit and ensure our systems employ **randomized exponential backoff**.”
	- "don’t forget that Google SRE != GCP SRE! Google’s internal infra is superior to that of GCP.  Amazon runs on AWS, Microsoft mostly on Azure, but Google does NOT run on GCP (not for their main rodicts at least!)"
	- https://status.openai.com/incidents/01JXCAW3K3JAE0EP56AEZ7CBG3/write-up
		- "On June 9 at 11:36  PM PDT, a routine update to the host Operating System on our cloud-hosted GPU servers caused a significant number of GPU nodes to lose network connectivity. This led to a drop in available capacity for our services. As a result, ChatGPT users experienced elevated error rates reaching ~35% errors at peak, while API users experienced error rates peaking at ~25%. The highest impact occurred between June 10 2:00  AM PDT and June 10 8:00  AM PDT. The engineering teams were alerted immediately at the start of the incident and worked diligently to restore service."
- https://github.com/hugobowne/building-with-ai/blob/main/notebooks/01-agentic-continuum.ipynb