- https://www.youtube.com/watch?v=TNpYuX5SbD0 Carl Jung : Khi bạn ngừng thể hiện cảm xúc, mọi thứ sẽ thay đổi
- https://vnexpress.net/gs-phan-van-truong-toi-nhu-con-ca-hoi-nguoc-dong-tim-ve-que-huong-4875395.html
	- Tôi rút ra 4 "chìa khóa" để một xã hội có thể tạo ra nhân tài
		- Thứ nhất là bình đẳng. Muốn xã hội có nhân tài, trước tiên phải có môi trường bình đẳng. Vào một căn phòng mà có ông tiến sĩ bảo: "Các bạn im đi, tôi là tiến sĩ" thì những người kia chẳng thể trở thành nhân tài. Tinh thần bình đẳng là ai cũng có thể đóng góp điều đặc biệt cho đất nước.
		- Chìa khóa thứ 2 là hồn nhiên. Làm việc và cống hiến một cách tự nhiên, không toan tính, không vụ lợi. Chỉ khi người ta tin vào môi trường, họ mới hồn nhiên mà trao đi năng lực của mình.
		- Thứ ba là thẳng thắn, chấp nhận tinh thần phản biện. Không có sự phát triển nào nếu người ta sợ nói thật.
		- Thứ tư là tích cực. Làm mọi thứ để đóng góp chứ không phải phá hoại.
- https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf
	- As you evaluate where agents can add value, prioritize workflows that have previously resisted automation, especially where traditional methods encounter friction:
		- Complex decision-making
		- Difficult-to-maintain rules
		- Heavy reliance on unstructured data
	- Before committing to building an agent, **validate that your use case can meet these criteria** clearly. Otherwise, **a deterministic solution** may suffice
- https://cookbook.openai.com/examples/responses_api/responses_api_tool_orchestration#multi-tool-orchestration-flow
- https://www.producthunt.com/posts/fire-1
	- https://www.firecrawl.dev/
- https://github.com/nagstler/mcp_on_ruby RE this, alongside with langchainrb Assistant
- https://www.bigbinary.com/blog/scaling-rails-series
- https://www.reddit.com/r/ollama/comments/1k0fn6y/how_do_you_finetune_a_model/
	- https://www.reddit.com/r/ollama/comments/1k0fn6y/comment/mndrgem/ -> "This is a vast simplification, but LLMs are essentially language-based probability engines. If I give you the sentence "In the summer, I like to eat ice" and ask you to give me the most probable next word, you would probably say "cream." LLMs are basically doing this as well on a larger scale. Training a model is essentially teaching it these probabilities, which are called weights. Fine tuning is giving it more weights, but weights that are relevant to your problem area or topic." pls read follow-up replies
- https://www.youtube.com/watch?v=rz9OT8PX6cI